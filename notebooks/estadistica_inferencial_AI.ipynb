# 1. Generaci√≥n de datos y contexto del problema

Vamos a simular un estudio sobre el rendimiento acad√©mico de estudiantes en funci√≥n de las horas de estudio semanales.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats
import math
from sklearn.linear_model import LinearRegression

# Creamos una semilla para reproducibilidad
np.random.seed(42)

# Generamos los datos
horas_estudio = np.random.normal(10, 3, 100)      # media 10 horas, desviaci√≥n 3
puntaje_examen = 40 + horas_estudio * 4 + np.random.normal(0, 5, 100)  # relaci√≥n con ruido

df = pd.DataFrame({
    'Horas_de_estudio': horas_estudio,
    'Puntaje_en_examen': puntaje_examen
})

df.head()

üßæ Explicaci√≥n:

Generamos una muestra de 100 estudiantes.

La variable Horas_de_estudio sigue una distribuci√≥n normal (media=10, sd=3).

El Puntaje_en_examen depende de las horas de estudio con cierta variaci√≥n aleatoria (ruido).

Esto representa una muestra, no toda la poblaci√≥n estudiantil.

# 2. Estimaci√≥n e Intervalo de Confianza

Queremos estimar el promedio poblacional del puntaje, con un nivel de confianza del 95%.

media = np.mean(puntaje_examen)
desv = np.std(puntaje_examen, ddof=1)
n = len(puntaje_examen)
confianza = 0.95
error = stats.t.ppf((1 + confianza) / 2, n - 1) * (desv / np.sqrt(n))

print(f"Media muestral: {media:.2f}")
print(f"Intervalo de confianza (95%): [{media - error:.2f}, {media + error:.2f}]")

üìò Explicaci√≥n:

Calculamos la media muestral, la desviaci√≥n est√°ndar y el intervalo de confianza.

El intervalo nos dice el rango en el que probablemente est√° el valor real (poblacional) de la media.

üß† Interpretaci√≥n:

Si la media muestral es 80.5 y el intervalo de confianza es [79.1, 81.9],
podemos decir con un 95% de confianza que el promedio real del puntaje poblacional est√° dentro de ese rango.

# 3.  Prueba de Hip√≥tesis

Queremos comprobar si el puntaje promedio poblacional es igual a 80.

t_stat, p_value = stats.ttest_1samp(puntaje_examen, 80)
print(f"T-statistic: {t_stat:.3f}")
print(f"P-value: {p_value:.3f}")

if p_value < 0.05:
    print("‚ùå Se rechaza H0: la media no es 80.")
else:
    print("‚úÖ No se rechaza H0: la media podr√≠a ser 80.")

 Explicaci√≥n:

H‚ÇÄ (hip√≥tesis nula): el promedio poblacional = 80

H‚ÇÅ (alternativa): el promedio es diferente de 80

Si el p-valor < 0.05, se rechaza H‚ÇÄ.

 Interpretaci√≥n:

Si el p-value = 0.12, significa que no hay evidencia suficiente para decir que la media es diferente de 80.
Por lo tanto, se mantiene la hip√≥tesis de que la media poblacional es 80.

# 4.  Correlaci√≥n y Covarianza

Queremos ver si aumentar las horas de estudio est√° relacionado con mejorar los puntajes.

# Correlaci√≥n
correlacion = df.corr()

# Covarianza
covarianza = np.cov(df['Horas_de_estudio'], df['Puntaje_en_examen'])

print("Matriz de correlaci√≥n:\n", correlacion, "\n")
print("Matriz de covarianza:\n", covarianza)

üìò Explicaci√≥n:

La correlaci√≥n (de Pearson) mide la fuerza y direcci√≥n de la relaci√≥n (entre -1 y 1).

La covarianza indica si las variables cambian juntas, pero depende de las unidades.

üß† Interpretaci√≥n:

Si la correlaci√≥n es 0.85, indica una relaci√≥n positiva fuerte:
m√°s horas de estudio ‚Üí mayores puntajes.

La covarianza positiva tambi√©n confirma esa tendencia.

# 5.  Prueba de Normalidad (Shapiro-Wilk)

Verificamos si los datos siguen una distribuci√≥n normal, requisito com√∫n en IA y estad√≠stica inferencial.

shap_horas = stats.shapiro(df['Horas_de_estudio'])
shap_puntaje = stats.shapiro(df['Puntaje_en_examen'])

print(f"P-valor Horas: {shap_horas.pvalue:.3f}")
print(f"P-valor Puntaje: {shap_puntaje.pvalue:.3f}")

Explicaci√≥n:

H‚ÇÄ: los datos provienen de una distribuci√≥n normal.

Si p < 0.05, los datos no son normales.

 Interpretaci√≥n:

Si p = 0.20 para puntajes, no se rechaza H‚ÇÄ ‚Üí los datos se pueden considerar normales.
Esto significa que se pueden aplicar m√©todos inferenciales como el test t o la regresi√≥n lineal.

# 6.  Regresi√≥n Lineal

Queremos construir un modelo predictivo que relacione las horas de estudio con el puntaje.
Esto conecta la estad√≠stica inferencial con la Inteligencia Artificial (aprendizaje supervisado).

X = df[['Horas_de_estudio']]
y = df['Puntaje_en_examen']

modelo = LinearRegression().fit(X, y)
pendiente = modelo.coef_[0]
intercepto = modelo.intercept_

print(f"Modelo: Puntaje = {intercepto:.2f} + {pendiente:.2f} * Horas_de_estudio")

df['Prediccion'] = modelo.predict(X)
df['Residuo'] = df['Puntaje_en_examen'] - df['Prediccion']

# Calcular RMSD
rmsd = math.sqrt(np.mean(df['Residuo']**2))
print(f"RMSD: {rmsd:.3f}")

 Explicaci√≥n:

Entrenamos un modelo lineal simple con scikit-learn.

La pendiente indica cu√°nto sube el puntaje por cada hora adicional de estudio.

El RMSD (Root Mean Square Deviation) mide el error promedio del modelo.

Interpretaci√≥n:

Si el modelo es Puntaje = 40.2 + 3.9 * Horas,
significa que cada hora adicional de estudio aumenta el puntaje en 3.9 puntos promedio.

Si el RMSD es 4.8, el modelo tiene un error promedio de ¬±4.8 puntos, lo cual es razonable.

# 7.  Visualizaci√≥n del modelo
plt.figure(figsize=(8,6))
plt.scatter(df['Horas_de_estudio'], df['Puntaje_en_examen'], color='skyblue', label='Datos reales')
plt.plot(df['Horas_de_estudio'], df['Prediccion'], color='red', label='Regresi√≥n lineal')
plt.xlabel('Horas de estudio semanales')
plt.ylabel('Puntaje en el examen')
plt.title(f'Regresi√≥n lineal (RMSD = {rmsd:.2f})')
plt.legend()
plt.grid(True)
plt.show()

Explicaci√≥n:

La gr√°fica muestra:

Los puntos reales de la muestra.

La l√≠nea roja de regresi√≥n ajustada.

Cuanto m√°s se acerquen los puntos a la l√≠nea, mejor se ajusta el modelo.

# Conclusiones

La estad√≠stica inferencial permiti√≥ estimar y verificar propiedades poblacionales (media, intervalos, hip√≥tesis).

Las pruebas estad√≠sticas (t, Shapiro, correlaci√≥n) mostraron c√≥mo validar supuestos.

La regresi√≥n lineal fue el paso hacia el modelado predictivo, base de la inteligencia artificial.

Este ejercicio demuestra c√≥mo los m√©todos inferenciales se integran al aprendizaje autom√°tico para comprender patrones y tomar decisiones basadas en datos.
